import os
# è®¾ç½®ç¯å¢ƒå˜é‡ä»¥é¿å…OpenMPé”™è¯¯
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE"

import streamlit as st
import torch
import torchvision.models as models
import torchvision.transforms as transforms
from torchvision.models import ResNet50_Weights
from PIL import Image
import numpy as np
import faiss
import json
from pathlib import Path
import os

# è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
st.set_page_config(
    page_title="å›¾åƒç›¸ä¼¼åº¦æ£€ç´¢ç³»ç»Ÿ",
    page_icon="ğŸ”",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("ğŸ” åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒç›¸ä¼¼åº¦æ£€ç´¢ç³»ç»Ÿ")
st.markdown("---")

# åˆå§‹åŒ–è®¾å¤‡
@st.cache_resource
def load_model():
    """åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶åˆå§‹åŒ–ç‰¹å¾æå–å™¨"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # åŠ è½½é¢„è®­ç»ƒResNetæ¨¡å‹å¹¶ä¿®æ”¹ä¸ºç‰¹å¾æå–å™¨
    weights = ResNet50_Weights.IMAGENET1K_V2
    model = models.resnet50(weights=weights).to(device)
    # å»é™¤æœ€åä¸¤å±‚ï¼ˆå…¨å±€å¹³å‡æ± åŒ–å±‚åç›´æ¥è¾“å‡ºç‰¹å¾ï¼Œæ— éœ€åˆ†ç±»å±‚ï¼‰
    feature_extractor = torch.nn.Sequential(*list(model.children())[:-1])
    feature_extractor.eval()  # è¿›å…¥è¯„ä¼°æ¨¡å¼ï¼Œç¦ç”¨Dropoutç­‰
    
    # å›¾åƒé¢„å¤„ç†ï¼ˆä¸é¢„è®­ç»ƒæ¨¡å‹è¦æ±‚ä¸€è‡´ï¼‰
    transform = transforms.Compose([
        transforms.Resize(256),  # å…ˆç¼©æ”¾åˆ°256ï¼ˆçŸ­è¾¹ï¼‰ï¼Œä¿æŒæ¯”ä¾‹
        transforms.CenterCrop(224),  # ä¸­å¿ƒè£å‰ªåˆ°224Ã—224ï¼ˆResNetæ ‡å‡†è¾“å…¥ï¼‰
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNetå‡å€¼
                             std=[0.229, 0.224, 0.225])   # ImageNetæ ‡å‡†å·®
    ])
    
    return feature_extractor, transform, device

# åŠ è½½æ¨¡å‹å’Œç›¸å…³ç»„ä»¶
feature_extractor, transform, device = load_model()

def extract_image_feature(image):
    """æå–å•å¼ å›¾åƒçš„ç‰¹å¾å‘é‡"""
    try:
        # å°†ä¸Šä¼ çš„PILå›¾åƒè½¬æ¢ä¸ºRGBæ ¼å¼
        image = image.convert("RGB")
        input_tensor = transform(image).unsqueeze(0).to(device)  # å¢åŠ æ‰¹æ¬¡ç»´åº¦
        
        # æ— æ¢¯åº¦è®¡ç®—åŠ é€Ÿ
        with torch.no_grad():
            feature = feature_extractor(input_tensor)
        
        # ç‰¹å¾å‘é‡å¤„ç†ï¼ˆå±•å¹³ä¸º1Då‘é‡å¹¶å½’ä¸€åŒ–ï¼‰
        feature_vector = feature.squeeze().cpu().numpy()
        # L2å½’ä¸€åŒ–ï¼ˆå¢åŠ è¾¹ç•Œæ¡ä»¶ï¼Œé¿å…é™¤ä»¥0ï¼‰
        norm = np.linalg.norm(feature_vector)
        feature_vector = feature_vector / norm if norm > 1e-6 else feature_vector
        return feature_vector.astype(np.float32)
    except Exception as e:
        st.error(f"ç‰¹å¾æå–å¤±è´¥ï¼š{e}")
        return None

# åŠ è½½å›¾åƒæ£€ç´¢æ•°æ®åº“
@st.cache_resource
def load_image_database():
    """åŠ è½½å›¾åƒç´¢å¼•å’Œå…ƒæ•°æ®"""
    db_dir = Path("./image_search_db")
    index_path = db_dir / "image_index.index"
    metadata_path = db_dir / "image_metadata.json"
    
    if not index_path.exists() or not metadata_path.exists():
        st.error("å›¾åƒæ£€ç´¢æ•°æ®åº“ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºæ•°æ®åº“ï¼")
        return None, []
    
    # åŠ è½½ç´¢å¼•ä¸å…ƒæ•°æ®
    loaded_index = faiss.read_index(str(index_path))
    with open(metadata_path, "r", encoding="utf-8") as f:
        loaded_img_metadata = json.load(f)
    
    return loaded_index, loaded_img_metadata

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°è®¾ç½®")
    top_k = st.slider("è¿”å›ç›¸ä¼¼å›¾åƒæ•°é‡", min_value=1, max_value=10, value=3)
    st.markdown("---")
    st.info("ğŸ’¡ ä½¿ç”¨è¯´æ˜ï¼š\n1. åœ¨ä¸‹æ–¹ä¸Šä¼ å¾…æ£€ç´¢çš„å›¾åƒ\n2. ç³»ç»Ÿä¼šè‡ªåŠ¨æå–å›¾åƒç‰¹å¾\n3. ä¸æ•°æ®åº“ä¸­çš„å›¾åƒè¿›è¡Œç›¸ä¼¼åº¦æ¯”è¾ƒ\n4. æ˜¾ç¤ºæœ€ç›¸ä¼¼çš„å›¾åƒç»“æœ")

# ä¸»ç•Œé¢ - å›¾åƒä¸Šä¼ åŒºåŸŸ
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ“¤ ä¸Šä¼ æŸ¥è¯¢å›¾åƒ")
    uploaded_file = st.file_uploader(
        "è¯·é€‰æ‹©ä¸€å¼ å›¾åƒè¿›è¡Œç›¸ä¼¼å›¾åƒæ£€ç´¢", 
        type=["jpg", "jpeg", "png"],
        help="æ”¯æŒJPGã€JPEGã€PNGæ ¼å¼çš„å›¾åƒæ–‡ä»¶"
    )

    if uploaded_file is not None:
        # æ˜¾ç¤ºä¸Šä¼ çš„å›¾åƒ
        image = Image.open(uploaded_file)
        st.image(image, caption="ä¸Šä¼ çš„æŸ¥è¯¢å›¾åƒ")

with col2:
    st.subheader("ğŸ“Š æ£€ç´¢ç»“æœ")
    
    if uploaded_file is not None:
        # åŠ è½½æ•°æ®åº“
        index, img_metadata = load_image_database()
        
        if index is not None:
            # æå–ä¸Šä¼ å›¾åƒçš„ç‰¹å¾
            with st.spinner('æ­£åœ¨æå–å›¾åƒç‰¹å¾...'):
                query_feature = extract_image_feature(image)
            
            if query_feature is not None:
                with st.spinner('æ­£åœ¨æ£€ç´¢ç›¸ä¼¼å›¾åƒ...'):
                    # è½¬æ¢ä¸ºåˆé€‚çš„å½¢çŠ¶å’Œç±»å‹
                    query_feature = query_feature.reshape(1, -1).astype(np.float32)
                    
                    # æ‰§è¡Œæ£€ç´¢
                    distances, indices = index.search(query_feature, top_k)
                
                # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
                st.success(f"æ‰¾åˆ° {top_k} ä¸ªæœ€ç›¸ä¼¼çš„å›¾åƒ")
                
                # å±•ç¤ºç»“æœ
                for i in range(top_k):
                    idx = indices[0][i]
                    distance = distances[0][i]
                    
                    # é˜²æ­¢ç´¢å¼•è¶Šç•Œ
                    if idx < 0 or idx >= len(img_metadata):
                        st.warning(f"æ’å {i+1}: æ— åŒ¹é…ç»“æœ")
                        continue
                    
                    # è·å–åŒ¹é…å›¾åƒä¿¡æ¯
                    matched_img_info = img_metadata[idx]
                    
                    # åˆ›å»ºç»“æœå¡ç‰‡
                    with st.container():
                        col_result_img, col_result_info = st.columns([1, 2])
                        
                        with col_result_img:
                            # å°è¯•æ˜¾ç¤ºåŒ¹é…çš„å›¾åƒ
                            try:
                                matched_img_path = matched_img_info['image_path']
                                if os.path.exists(matched_img_path):
                                    matched_img = Image.open(matched_img_path)
                                    st.image(matched_img, caption=f"åŒ¹é…å›¾åƒ {i+1}")
                                else:
                                    st.warning(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {matched_img_path}")
                            except Exception as e:
                                st.warning(f"æ— æ³•åŠ è½½åŒ¹é…å›¾åƒ: {e}")
                        
                        with col_result_info:
                            st.markdown(f"**æ’å {i+1}**")
                            st.markdown(f"L2è·ç¦»: **{distance:.4f}**")
                            st.markdown(f"äº§å“ID: `{matched_img_info['product_id']}`")
                            st.markdown(f"ç±»åˆ«: `{matched_img_info['category']}`")
                            st.text(f"è·¯å¾„: {matched_img_info['image_path']}")
                        
                        st.markdown("---")
            else:
                st.error("å›¾åƒç‰¹å¾æå–å¤±è´¥ï¼Œè¯·å°è¯•å…¶ä»–å›¾åƒ")
        else:
            st.error("æ— æ³•åŠ è½½å›¾åƒæ£€ç´¢æ•°æ®åº“")
    else:
        st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ ä¸€å¼ å›¾åƒä»¥å¼€å§‹æ£€ç´¢")

# åº•éƒ¨ä¿¡æ¯
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>åŸºäº ResNet50 + FAISS çš„å›¾åƒç›¸ä¼¼åº¦æ£€ç´¢ç³»ç»Ÿ</p>
    <p>ä½¿ç”¨æ·±åº¦å­¦ä¹ æå–å›¾åƒç‰¹å¾ï¼Œé€šè¿‡L2è·ç¦»è®¡ç®—å›¾åƒç›¸ä¼¼åº¦</p>
</div>
""", unsafe_allow_html=True)